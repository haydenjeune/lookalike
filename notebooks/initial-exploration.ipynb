{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circular-property",
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import torch\n",
    "from PIL import Image\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-butter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a face detection pipeline using MTCNN:\n",
    "mtcnn = MTCNN(margin=20, select_largest=True)\n",
    "\n",
    "# Create an inception resnet (in eval mode):\n",
    "resnet = InceptionResnetV1(pretrained='vggface2').eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-cache",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embedding(image: Image) -> torch.Tensor:\n",
    "    # Get cropped and prewhitened image tensor\n",
    "    cropped = mtcnn(image)\n",
    "\n",
    "    # Calculate embedding (unsqueeze to add batch dimension, squeeze to remove it again)\n",
    "    embedding = resnet(cropped.unsqueeze(0)).squeeze()\n",
    "    \n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hazardous-fortune",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "me = Image.open(\"data/github-profile.jpeg\")\n",
    "queen = Image.open(\"data/qe2.jpeg\")\n",
    "ryan_reynolds = Image.open(\"data/ryan-reynolds.jpeg\")\n",
    "chris_odowd = Image.open(\"data/chris-odowd.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cheap-california",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get embeddings\n",
    "me_vec = generate_embedding(me)\n",
    "queen_vec = generate_embedding(queen)\n",
    "ryan_reynolds_vec = generate_embedding(ryan_reynolds)\n",
    "chris_odowd_vec = generate_embedding(chris_odowd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-defense",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(a: torch.Tensor, b: torch.Tensor) -> float:\n",
    "    # just a dot product scaled between 0 and 1 for now\n",
    "    return (torch.dot(a, b).tolist() + 1) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superior-singer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Who do i look most like?\n",
    "print(f\"I look {similarity(me_vec, queen_vec)*100}% like the Queen\")\n",
    "print(f\"I look {similarity(me_vec, ryan_reynolds_vec)*100}% like Ryan Reynolds\")\n",
    "print(f\"I look {similarity(me_vec, chris_odowd_vec)*100}% like Chris O'Dowd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moderate-forty",
   "metadata": {},
   "source": [
    "Well, the numbers are a bit closer than I'd hoped, but seem to be directionally correct!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-animation",
   "metadata": {},
   "outputs": [],
   "source": [
    "ryan_reynolds_2 = Image.open(\"data/ryan-reynolds-2.jpeg\")\n",
    "ryan_reynolds_2_vec = generate_embedding(ryan_reynolds_2)\n",
    "\n",
    "print(f\"Ryan Reynolds looks {similarity(ryan_reynolds_vec, ryan_reynolds_2_vec)*100}% like Ryan Reynolds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-turner",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}